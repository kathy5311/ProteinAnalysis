{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import torch\n",
    "device = torch.device(\"cuda:0\" if (torch.cuda.is_available()) else \"cpu\")\n",
    "#import models\n",
    "import numpy as np\n",
    "\n",
    "#model\n",
    "import torch.nn as nn\n",
    "\n",
    "MAXEPOCH=100\n",
    "BATCH=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, nlayer=4, dropout=0.1):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "\n",
    "        drop = torch.nn.Dropout(p=dropout)\n",
    "        conv1 = torch.nn.Conv1d(21,32,3,padding=1) # aa1hot,channel,\n",
    "        layers = [drop,conv1]\n",
    "        \n",
    "        for k in range(nlayer):\n",
    "            conv2 = torch.nn.Conv1d(32,32,3,padding=1) # aa1hot,channel,\n",
    "            layers.append(conv2)\n",
    "            layers.append(nn.BatchNorm1d(32))\n",
    "            layers.append(nn.ReLU(inplace=True))\n",
    "\n",
    "        self.layers = nn.ModuleList(layers)\n",
    "\n",
    "        # 1 x 32 x nres\n",
    "        self.outlayer = nn.Linear(32,3)\n",
    "        \n",
    "    def forward(self, seq):\n",
    "        #pred = seq # should B x 20 x nres\n",
    "        for layer in self.layers:\n",
    "            seq = layer(seq)\n",
    "\n",
    "        seq = torch.transpose(seq,1,2) # put channel at the last\n",
    "        \n",
    "        pred = self.outlayer(seq)\n",
    "        pred = torch.transpose(pred,2,1)\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataSet(torch.utils.data.Dataset):\n",
    "    def __init__(self, datalist): #idx제거\n",
    "        self.tags = [tag for tag in datalist if not tag.endswith('.DS_Store')]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.tags)\n",
    "\n",
    "    def __getitem__(self,index):\n",
    "        npz = self.tags[index]\n",
    "        #print(npz)\n",
    "          \n",
    "        data = np.load(npz,allow_pickle=True)\n",
    "\n",
    "        aas = 'ACDEFGHIKLMNPQRSTVWYX'\n",
    "        SS3 = 'HEC'\n",
    "    \n",
    "        seqs = [aas.index(a) for a in  data['sequence']]#변수 명 바꿈\n",
    "        #print(seqs)\n",
    "        SSs  = [SS3.index(a) for a in data['SS']]\n",
    "        \n",
    "        seq1hot = np.transpose(np.eye(21)[seqs],(1,0)) # 20xnres #tensor size 20으로 바꿈.\n",
    "        #np.eye(21)[seqs]=> 21x21항등행렬을 만드는데 seqs에 맞게 설정된 항등행렬을 만들어라.\n",
    "        \n",
    "        SS1hot = np.transpose(np.eye(3)[SSs],(1,0)) #np.eye는 항등행렬을 생성해줌\n",
    "        #print(SS1hot)\n",
    "        return seq1hot, SSs, seq1hot.shape[1] #SSs[index]??->SS1hot\n",
    "        #seq1hot.shape[1]=시퀀스의 길이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate(samples): # 같은 배치 안에 길이가 가장 긴 input에 맞춰 다른 input들에 임의로 zero-padding.\n",
    "    seq,SS,nres = map(list, zip(*samples))\n",
    "    valid = [i for i,n in enumerate(nres) if n > 50]\n",
    "    #print(valid)\n",
    "    if len(valid) == 0: return [],[]\n",
    "    \n",
    "    seq = [seq[i] for i in valid]\n",
    "    SS = [SS[i] for i in valid]\n",
    "    \n",
    "    nres = max(nres)\n",
    "    B = len(seq)\n",
    "\n",
    "    # map into maxres\n",
    "    seqs = torch.zeros(B,21,nres)\n",
    "    #print(seqs)\n",
    "    SSs  = torch.zeros(B,nres,dtype=torch.long)\n",
    "    for i,s in enumerate(seq): #seqs는 0한 개로만 이루어진 리스트다. 때문에 i는 0만 출력된다.\n",
    "        #print(i)\n",
    "        seqs[i][:len(s[1])] = torch.tensor(s) \n",
    "    for i,s in enumerate(SS): \n",
    "        #print(i)\n",
    "        SSs[i][:len(s)] = torch.tensor(s)\n",
    "\n",
    "    return seqs, SSs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/Valid:   0   0.9880   0.9586\n",
      "Train/Valid:   1   0.9401   0.9432\n",
      "Train/Valid:   2   0.9136   0.9143\n",
      "Train/Valid:   3   0.8964   0.9082\n",
      "Train/Valid:   4   0.8755   0.9005\n",
      "Train/Valid:   5   0.8634   0.8858\n",
      "Train/Valid:   6   0.8450   0.8782\n",
      "Train/Valid:   7   0.8255   0.8599\n",
      "Train/Valid:   8   0.8166   0.8637\n",
      "Train/Valid:   9   0.8046   0.8630\n",
      "Train/Valid:  10   0.7900   0.8479\n",
      "Train/Valid:  11   0.7781   0.8251\n",
      "Train/Valid:  12   0.7567   0.8212\n",
      "Train/Valid:  13   0.7397   0.8096\n",
      "Train/Valid:  14   0.7327   0.8080\n",
      "Train/Valid:  15   0.7167   0.7948\n",
      "Train/Valid:  16   0.6985   0.7851\n",
      "Train/Valid:  17   0.7063   0.7843\n",
      "Train/Valid:  18   0.6884   0.7811\n",
      "Train/Valid:  19   0.6922   0.8130\n",
      "Train/Valid:  20   0.7018   0.8269\n",
      "Train/Valid:  21   0.7187   0.7617\n",
      "Train/Valid:  22   0.7014   0.7838\n",
      "Train/Valid:  23   0.6909   0.7798\n",
      "Train/Valid:  24   0.6746   0.7696\n",
      "Train/Valid:  25   0.6801   0.7679\n",
      "Train/Valid:  26   0.6638   0.7606\n",
      "Train/Valid:  27   0.6603   0.7574\n",
      "Train/Valid:  28   0.6606   0.7340\n",
      "Train/Valid:  29   0.6605   0.8106\n",
      "Train/Valid:  30   0.6689   0.7710\n",
      "Train/Valid:  31   0.6571   0.7706\n",
      "Train/Valid:  32   0.6497   0.7527\n",
      "Train/Valid:  33   0.6540   0.7347\n",
      "Train/Valid:  34   0.6519   0.7707\n",
      "Train/Valid:  35   0.6632   0.7634\n",
      "Train/Valid:  36   0.6501   0.7823\n",
      "Train/Valid:  37   0.6546   0.7860\n",
      "Train/Valid:  38   0.6441   0.7654\n",
      "Train/Valid:  39   0.6366   0.7329\n",
      "Train/Valid:  40   0.6301   0.7646\n",
      "Train/Valid:  41   0.6306   0.7326\n",
      "Train/Valid:  42   0.6281   0.7501\n"
     ]
    }
   ],
   "source": [
    "model = CNN()\n",
    "model.to(device)\n",
    "\n",
    "## load dataset\n",
    "trainlist = np.load('train.npy')\n",
    "validlist = np.load('valid.npy')\n",
    "\n",
    "trainset = DataSet(trainlist)\n",
    "validset = DataSet(validlist)\n",
    "\n",
    "generator_params = {\n",
    "    'shuffle': True,\n",
    "    'num_workers': 0, #num_worker 오류가 나서 0으로 바꿔줌.\n",
    "    'pin_memory': True,\n",
    "    'collate_fn': collate,\n",
    "    'batch_size': BATCH,\n",
    "    'worker_init_fn' : np.random.seed()\n",
    "}\n",
    "train_generator = torch.utils.data.DataLoader(trainset, **generator_params)\n",
    "valid_generator = torch.utils.data.DataLoader(validset, **generator_params)\n",
    " \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1.0e-4)\n",
    "\n",
    "lossfunc = torch.nn.CrossEntropyLoss()\n",
    "for epoch in range(MAXEPOCH):  #seq를 보고 이차구조(SS)를 예측하는 것이 goal\n",
    "    loss_t = []\n",
    "    for i,(seq,SS) in enumerate(train_generator):\n",
    "        if len(seq) == 0: continue\n",
    "        \n",
    "        # get prediction\n",
    "        SSpred = model(seq.to(device))\n",
    "        \n",
    "        # calculate loss\n",
    "        SS = SS.to(device)\n",
    "        loss = lossfunc(SSpred,SS)\n",
    "        loss.backward(retain_graph=True)\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_t.append(loss.cpu().detach().numpy())\n",
    "    #print(\"TRAIN:\", epoch, float(np.mean(loss_)))\n",
    "        \n",
    "    loss_v = []\n",
    "    for i,(seq,SS) in enumerate(valid_generator):\n",
    "        if len(seq) == 0: continue        \n",
    "        # get prediction\n",
    "        SSpred = model(seq.to(device))\n",
    "        SS_valid=SSpred\n",
    "        \n",
    "        # calculate loss\n",
    "        SS = SS.to(device)\n",
    "        loss = lossfunc(SSpred,SS)\n",
    "        loss_v.append(loss.cpu().detach().numpy())\n",
    "        \n",
    "    print(\"Train/Valid: %3d %8.4f %8.4f\"%(epoch, float(np.mean(loss_t)), float(np.mean(loss_v))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_train=0\n",
    "total_train=0\n",
    "for i, (seq, SS) in enumerate(train_generator):\n",
    "\n",
    "    if len(seq)==0:\n",
    "        continue\n",
    "    #print(seq)\n",
    "    SSpred=model(seq.to(device))\n",
    "\n",
    "    predicted = torch.argmax(SSpred.data,1)\n",
    "\n",
    "    correct_train += torch.sum(predicted == SS.to(device)).item()\n",
    "\n",
    "    SS_squeeze=SS.squeeze()\n",
    "    SS_squeeze_1=SS_squeeze.squeeze()\n",
    "    total_train+=SS_squeeze_1.size(0)\n",
    "\n",
    "accuracy_train=correct_train/total_train  \n",
    "print(accuracy_train*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_valid=0\n",
    "total_valid=0\n",
    "for i, (seq, SS) in enumerate(valid_generator):\n",
    "\n",
    "    if len(seq)==0:\n",
    "        continue\n",
    "    #print(seq)\n",
    "    SSpred=model(seq.to(device))\n",
    "\n",
    "    predicted = torch.argmax(SSpred.data,1)\n",
    "\n",
    "    correct_valid += torch.sum(predicted == SS.to(device)).item()\n",
    "\n",
    "    SS_squeeze=SS.squeeze()\n",
    "    SS_squeeze_1=SS_squeeze.squeeze()\n",
    "    total_valid+=SS_squeeze_1.size(0)\n",
    "\n",
    "accuracy_valid=correct_valid/total_valid  \n",
    "print(accuracy_valid*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#confusion matrix-train_set\n",
    "for i, (seq, SS) in enumerate(train_generator):\n",
    "    if len(seq)==0:\n",
    "        continue\n",
    "    \n",
    "    SSpred=model(seq.to(device))\n",
    "    \n",
    "    predicted = torch.argmax(SSpred.data,dim=1)\n",
    "    \n",
    "    cm=confusion_matrix(SS.to(device).detach().numpy().flatten(), predicted.detach().numpy().flatten())\n",
    "    print(cm)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#confusion matrix-test_set\n",
    "for i, (seq, SS) in enumerate(valid_generator):\n",
    "    if len(seq)==0:\n",
    "        continue\n",
    "    \n",
    "    SSpred=model(seq.to(device))\n",
    "    \n",
    "    predicted = torch.argmax(SSpred.data,dim=1)\n",
    "    \n",
    "    cm=confusion_matrix(SS.to(device).detach().numpy().flatten(), predicted.detach().numpy().flatten())\n",
    "    print(cm)\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RDKit",
   "language": "python",
   "name": "rdkit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
