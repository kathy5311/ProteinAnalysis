{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPjqeJgajK2Ic5Eo8lJ6dXA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kathy5311/ProteinAnalysis/blob/main/SS_prediction_revise.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "FMELNm67XBGs"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import torch\n",
        "device = torch.device(\"cuda:0\" if (torch.cuda.is_available()) else \"cpu\")\n",
        "#import models\n",
        "import numpy as np\n",
        "\n",
        "#model\n",
        "import torch.nn as nn\n",
        "\n",
        "MAXEPOCH=100\n",
        "BATCH=1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self, nlayer=4, dropout=0.1):\n",
        "        super().__init__()\n",
        "        layers = []\n",
        "\n",
        "        drop = torch.nn.Dropout(p=dropout)\n",
        "        conv1 = torch.nn.Conv1d(21,32,3,padding=1) # aa1hot,channel,\n",
        "        layers = [drop,conv1]\n",
        "\n",
        "        for k in range(nlayer):\n",
        "            conv2 = torch.nn.Conv1d(32,32,3,padding=1) # aa1hot,channel,\n",
        "            layers.append(conv2)\n",
        "            layers.append(nn.BatchNorm1d(32))\n",
        "            layers.append(nn.ReLU(inplace=True))\n",
        "\n",
        "        self.layers = nn.ModuleList(layers)\n",
        "\n",
        "        # 1 x 32 x nres\n",
        "        self.outlayer = nn.Linear(32,3)\n",
        "\n",
        "    def forward(self, seq):\n",
        "        #pred = seq # should B x 20 x nres\n",
        "        for layer in self.layers:\n",
        "            seq = layer(seq)\n",
        "\n",
        "        seq = torch.transpose(seq,1,2) # put channel at the last\n",
        "\n",
        "        pred = self.outlayer(seq)\n",
        "        pred = torch.transpose(pred,2,1)\n",
        "        return pred"
      ],
      "metadata": {
        "id": "59l_6tXrYRZ8"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DataSet(torch.utils.data.Dataset):\n",
        "    def __init__(self, datalist): #idx제거\n",
        "        self.tags = [tag for tag in datalist if not tag.endswith('.DS_Store')]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.tags)\n",
        "\n",
        "    def __getitem__(self,index):\n",
        "        npz = self.tags[index]\n",
        "        #print(npz)\n",
        "\n",
        "        data = np.load(npz,allow_pickle=True)\n",
        "\n",
        "        aas = 'ACDEFGHIKLMNPQRSTVWYX'\n",
        "        SS3 = 'HEC'\n",
        "\n",
        "        seqs = [aas.index(a) for a in  data['sequence']]#변수 명 바꿈\n",
        "        #print(seqs)\n",
        "        SSs  = [SS3.index(a) for a in data['SS']]\n",
        "\n",
        "        seq1hot = np.transpose(np.eye(21)[seqs],(1,0)) # 20xnres #tensor size 20으로 바꿈.\n",
        "        #np.eye(21)[seqs]=> 21x21항등행렬을 만드는데 seqs에 맞게 설정된 항등행렬을 만들어라.\n",
        "\n",
        "        SS1hot = np.transpose(np.eye(3)[SSs],(1,0)) #np.eye는 항등행렬을 생성해줌\n",
        "        #print(SS1hot)\n",
        "        return seq1hot, SSs, seq1hot.shape[1] #SSs[index]??->SS1hot\n",
        "        #seq1hot.shape[1]=시퀀스의 길이다.\n",
        "\n",
        "def collate(samples): # 같은 배치 안에 길이가 가장 긴 input에 맞춰 다른 input들에 임의로 zero-padding.\n",
        "    seq,SS,nres = map(list, zip(*samples))\n",
        "    valid = [i for i,n in enumerate(nres) if n > 50]\n",
        "    #print(valid)\n",
        "    if len(valid) == 0: return [],[]\n",
        "\n",
        "    seq = [seq[i] for i in valid]\n",
        "    SS = [SS[i] for i in valid]\n",
        "\n",
        "    nres = max(nres)\n",
        "    B = len(seq)\n",
        "\n",
        "    # map into maxres\n",
        "    seqs = torch.zeros(B,21,nres)\n",
        "    #print(seqs)\n",
        "    SSs  = torch.zeros(B,nres,dtype=torch.long)\n",
        "    for i,s in enumerate(seq): #seqs는 0한 개로만 이루어진 리스트다. 때문에 i는 0만 출력된다.\n",
        "        #print(i)\n",
        "        seqs[i][:len(s[1])] = torch.tensor(s)\n",
        "    for i,s in enumerate(SS):\n",
        "        #print(i)\n",
        "        SSs[i][:len(s)] = torch.tensor(s)\n",
        "\n",
        "    return seqs, SSs"
      ],
      "metadata": {
        "id": "FwZel1VjYUdZ"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = CNN()\n",
        "model.to(device)\n",
        "\n",
        "## load dataset\n",
        "trainlist = np.load('train.npy')\n",
        "validlist = np.load('valid.npy')\n",
        "\n",
        "trainset = DataSet(trainlist)\n",
        "validset = DataSet(validlist)\n",
        "\n",
        "generator_params = {\n",
        "    'shuffle': True,\n",
        "    'num_workers': 0, #num_worker 오류가 나서 0으로 바꿔줌.\n",
        "    'pin_memory': True,\n",
        "    'collate_fn': collate,\n",
        "    'batch_size': BATCH,\n",
        "    'worker_init_fn' : np.random.seed()\n",
        "}\n",
        "train_generator = torch.utils.data.DataLoader(trainset, **generator_params)\n",
        "valid_generator = torch.utils.data.DataLoader(validset, **generator_params)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1.0e-4)\n",
        "\n",
        "lossfunc = torch.nn.CrossEntropyLoss()\n",
        "for epoch in range(MAXEPOCH):  #seq를 보고 이차구조(SS)를 예측하는 것이 goal\n",
        "    loss_t = []\n",
        "    for i,(seq,SS) in enumerate(train_generator):\n",
        "        if len(seq) == 0: continue\n",
        "\n",
        "        # get prediction\n",
        "        SSpred = model(seq.to(device))\n",
        "\n",
        "        # calculate loss\n",
        "        SS = SS.to(device)\n",
        "        loss = lossfunc(SSpred,SS)\n",
        "        loss.backward(retain_graph=True)\n",
        "        optimizer.step()\n",
        "\n",
        "        loss_t.append(loss.cpu().detach().numpy())\n",
        "    #print(\"TRAIN:\", epoch, float(np.mean(loss_)))\n",
        "\n",
        "    loss_v = []\n",
        "    for i,(seq,SS) in enumerate(valid_generator):\n",
        "        if len(seq) == 0: continue\n",
        "        # get prediction\n",
        "        SSpred = model(seq.to(device))\n",
        "        SS_valid=SSpred\n",
        "\n",
        "        # calculate loss\n",
        "        SS = SS.to(device)\n",
        "        loss = lossfunc(SSpred,SS)\n",
        "        loss_v.append(loss.cpu().detach().numpy())\n",
        "\n",
        "    print(\"Train/Valid: %3d %8.4f %8.4f\"%(epoch, float(np.mean(loss_t)), float(np.mean(loss_v))))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KRtvIuLZYX_y",
        "outputId": "20b808df-0ebd-4a63-83d6-9d98f5207125"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train/Valid:   0   1.0010   0.9590\n",
            "Train/Valid:   1   0.9462   0.9356\n",
            "Train/Valid:   2   0.9163   0.9207\n",
            "Train/Valid:   3   0.8954   0.9052\n",
            "Train/Valid:   4   0.8767   0.9013\n",
            "Train/Valid:   5   0.8585   0.8890\n",
            "Train/Valid:   6   0.8419   0.8797\n",
            "Train/Valid:   7   0.8278   0.8808\n",
            "Train/Valid:   8   0.8123   0.8583\n",
            "Train/Valid:   9   0.7973   0.8644\n",
            "Train/Valid:  10   0.7821   0.8544\n",
            "Train/Valid:  11   0.7658   0.8329\n",
            "Train/Valid:  12   0.7636   0.8405\n",
            "Train/Valid:  13   0.7542   0.8190\n",
            "Train/Valid:  14   0.7344   0.8488\n",
            "Train/Valid:  15   0.7237   0.8247\n",
            "Train/Valid:  16   0.7091   0.8292\n",
            "Train/Valid:  17   0.7098   0.8155\n",
            "Train/Valid:  18   0.6990   0.8098\n",
            "Train/Valid:  19   0.6964   0.8021\n",
            "Train/Valid:  20   0.7012   0.8152\n",
            "Train/Valid:  21   0.7019   0.7887\n",
            "Train/Valid:  22   0.7179   0.8778\n",
            "Train/Valid:  23   0.7065   0.8038\n",
            "Train/Valid:  24   0.6883   0.8312\n",
            "Train/Valid:  25   0.6951   0.7896\n",
            "Train/Valid:  26   0.6869   0.8137\n",
            "Train/Valid:  27   0.6688   0.7803\n",
            "Train/Valid:  28   0.6653   0.7892\n",
            "Train/Valid:  29   0.6581   0.7843\n",
            "Train/Valid:  30   0.6500   0.7803\n",
            "Train/Valid:  31   0.6491   0.8021\n",
            "Train/Valid:  32   0.6446   0.7693\n",
            "Train/Valid:  33   0.6420   0.7627\n",
            "Train/Valid:  34   0.6353   0.7655\n",
            "Train/Valid:  35   0.6279   0.7784\n",
            "Train/Valid:  36   0.6297   0.7769\n",
            "Train/Valid:  37   0.6264   0.7603\n",
            "Train/Valid:  38   0.6203   0.7826\n",
            "Train/Valid:  39   0.6213   0.7875\n",
            "Train/Valid:  40   0.6281   0.7521\n",
            "Train/Valid:  41   0.6308   0.7672\n",
            "Train/Valid:  42   0.6220   0.7708\n",
            "Train/Valid:  43   0.6252   0.7460\n",
            "Train/Valid:  44   0.6219   0.8050\n",
            "Train/Valid:  45   0.6194   0.7505\n",
            "Train/Valid:  46   0.6210   0.7881\n",
            "Train/Valid:  47   0.6211   0.7700\n",
            "Train/Valid:  48   0.6192   0.7570\n",
            "Train/Valid:  49   0.6126   0.7622\n",
            "Train/Valid:  50   0.6152   0.7570\n",
            "Train/Valid:  51   0.6100   0.7654\n",
            "Train/Valid:  52   0.6142   0.7329\n",
            "Train/Valid:  53   0.6063   0.7602\n",
            "Train/Valid:  54   0.6027   0.7381\n",
            "Train/Valid:  55   0.6051   0.7457\n",
            "Train/Valid:  56   0.6107   0.7812\n",
            "Train/Valid:  57   0.6157   0.7480\n",
            "Train/Valid:  58   0.6047   0.7986\n",
            "Train/Valid:  59   0.5995   0.7368\n",
            "Train/Valid:  60   0.6032   0.7865\n",
            "Train/Valid:  61   0.5947   0.7573\n",
            "Train/Valid:  62   0.5994   0.7928\n",
            "Train/Valid:  63   0.5958   0.7439\n",
            "Train/Valid:  64   0.5907   0.7555\n",
            "Train/Valid:  65   0.5849   0.7382\n",
            "Train/Valid:  66   0.5860   0.7469\n",
            "Train/Valid:  67   0.5869   0.7588\n",
            "Train/Valid:  68   0.5918   0.7374\n",
            "Train/Valid:  69   0.5853   0.7569\n",
            "Train/Valid:  70   0.5834   0.7519\n",
            "Train/Valid:  71   0.5807   0.7410\n",
            "Train/Valid:  72   0.5792   0.7552\n",
            "Train/Valid:  73   0.5781   0.7193\n",
            "Train/Valid:  74   0.5771   0.7381\n",
            "Train/Valid:  75   0.5749   0.7904\n",
            "Train/Valid:  76   0.5762   0.7319\n",
            "Train/Valid:  77   0.5773   0.7311\n",
            "Train/Valid:  78   0.5735   0.7327\n",
            "Train/Valid:  79   0.5798   0.7256\n",
            "Train/Valid:  80   0.5794   0.7384\n",
            "Train/Valid:  81   0.5757   0.7281\n",
            "Train/Valid:  82   0.5723   0.7234\n",
            "Train/Valid:  83   0.5697   0.7390\n",
            "Train/Valid:  84   0.5738   0.7151\n",
            "Train/Valid:  85   0.5773   0.7148\n",
            "Train/Valid:  86   0.5769   0.7730\n",
            "Train/Valid:  87   0.5776   0.7389\n",
            "Train/Valid:  88   0.5736   0.7267\n",
            "Train/Valid:  89   0.5694   0.7380\n",
            "Train/Valid:  90   0.5745   0.7687\n",
            "Train/Valid:  91   0.5705   0.7288\n",
            "Train/Valid:  92   0.5660   0.7310\n",
            "Train/Valid:  93   0.5677   0.7295\n",
            "Train/Valid:  94   0.5715   0.7413\n",
            "Train/Valid:  95   0.5723   0.7283\n",
            "Train/Valid:  96   0.5706   0.7133\n",
            "Train/Valid:  97   0.5687   0.7371\n",
            "Train/Valid:  98   0.5660   0.7267\n",
            "Train/Valid:  99   0.5609   0.7714\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "correct_train=0\n",
        "total_train=0\n",
        "for i, (seq, SS) in enumerate(train_generator):\n",
        "\n",
        "    if len(seq)==0:\n",
        "        continue\n",
        "    #print(seq)\n",
        "    SSpred=model(seq.to(device))\n",
        "\n",
        "    predicted = torch.argmax(SSpred.data,1)\n",
        "\n",
        "    correct_train += torch.sum(predicted == SS.to(device)).item()\n",
        "\n",
        "    SS_squeeze=SS.squeeze()\n",
        "    SS_squeeze_1=SS_squeeze.squeeze()\n",
        "    total_train+=SS_squeeze_1.size(0)\n",
        "\n",
        "accuracy_train=correct_train/total_train\n",
        "print(accuracy_train*100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NEteuaOOYazk",
        "outputId": "e2732b04-3af3-4413-c991-ce1a42b5b9a8"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "72.97508404192209\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PXheKkUHYdNi"
      },
      "execution_count": 48,
      "outputs": []
    }
  ]
}